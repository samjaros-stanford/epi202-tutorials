---
title: "Week 5: Data Manipulation"
output: html_notebook
---

# Week 5: Data Manipulation

Welcome to Week 5! This week, we'll introduce methods for data manipulation, or the alteration of data frames to gain new insights from the data. This tutorial will cover different methods to create new variables, combine datasets, and reshape data frames.

Before you start, run the cell below to load the required packages.

```{r}
library(tidyverse) # also loads dplyr
library(here)
```

We'll continue to work with the Framingham data in this tutorial. You should already have this data installed from the Week 4 Tutorial. If not, refer back to last week's tutorial for how to properly install and store the data file. Run the code below to load the data as `framingham_df`. If you need refresher to the `here` function, you may also review the Week 4 tutorial.

```{r}
framingham_df = read_csv(here("data", "framingham.csv"))
head(framingham_df)
```

We'll also use simulated (ie generated by a computer, not through real-world data collection) demographic data at the end of this tutorial. Download the "framingham_zip_demog.csv" dataset from Canvas and move it to the `data` folder of your class directory. Run the next cell to load the data and name the data frame `zip_code_demog`

```{r}
zip_code_demog = read_csv(here("data", "framingham_zip_demog.csv"))
head(zip_code_demog)
```

# Data Cleaning

Real world data, particularly those used in health research, are quite "messy". Missing values, duplicate rows, and data entry errors may be present, and can change inferences from our data if not handled correctly. Luckily, dplyr includes many functions that can assist with data cleaning.

## replace_na()

By default, missing values are coded in R as `NA` but it might be more informative to have them listed as something else like "Not measured" or "Unknown".

We can start by looking at the degree of missingness in the `education` column

```{r}
framingham_df %>% filter(is.na(education))
```

We see that there were \>100 missing education values. However, when we use `table()` with its default arguments, missing values will be excluded.

```{r}
framingham_df %>% pull(education) %>% table()
```

If we keep these `education` values as `NA`, they might get filtered out in downstream analyses but it's important to report how many missing values are in the dataset. We can use `replace_na()` to replace missing values with 0.

```{r}
replaced_edu_nas_framingham = 
  framingham_df %>% 
  replace_na(list(education = 0)) # NA values in the education columns are replaced with "Unknown" 
replaced_edu_nas_framingham %>% pull(education) %>% table() 
```

## Removing duplicates

There might be extra copies of some rows in your dataset (can be a result of an upstream data processing error). If we leave them in our data, these data points will incorrectly carry more weight and introduce bias to our analysis.

We can identify duplicated rows in our dataset using the `duplicated` function, which takes in a data frame as an argument and returns a vector of logicals that are TRUE if a row appears multiple times in the dataset and FALSE if the row only appears once.

```{r}
framingham_duplicated_indices = duplicated(framingham_df)
table(framingham_duplicated_indices) 
```

It appears that there's one row in the dataset that is duplicated; note that `duplicated` will not flag the first instance of duplicated rows. For example, if a row appears 3 times in the dataset `duplicated` will only return 2 `TRUE`s for that set. If a row appears 11 times in the dataset `duplicated` will only return 10 `TRUE`s for that set

We can view what rows are duplicated by indexing the data frame with `framingham_duplicated_indices` (see Week 2 for a refresher)

```{r}
framingham_df[framingham_duplicated_indices, ]
```

Participant 46 had 2 rows in the dataset. We want to remove this duplicate, so only one copy of the row is included in our analysis dataset. The `distinct()` function can be applied to keep only unique rows in a dataset. The code below creates a new data frame `framingham_deduplicated` that removes the duplicated row we identified above, and compared the number of rows between the original and deduplicated datasets.

```{r}
framingham_deduplicated = framingham_df %>% distinct()
paste("The original dataset has", nrow(framingham_df), "rows.")
paste("The deduplicated dataset has", nrow(framingham_deduplicated), "rows.")
```

## Handling (Erroneous) Outliers

Outliers are data points that deviate significantly other values in the dataset. These points can represent true, extreme cases but may also be a result of measurement error. In these cases, outliers can skew the results of an analysis, so it's critical to account for any extreme values that arise from errors in measurement or data entry.

For example, BMIs that are very low can be fatal in adults and the lowest BMI recorded was 6.4 kg/m\^2. In our dataset, it's unlikely that we'll observe extremely low BMIs (\<5 kg/m\^2), especially if other data points indicate that they're healthy.

To determine if there are any outliers that need to be handled, we can first see if there are any instances where BMI is less than 5

```{r}
framingham_df %>% 
  filter(BMI < 5) %>% # Filters dataset to only rows where BMI < 5
  pull(BMI) # Pull BMI column as vector
```

It looks like 1 individual had a BMI of 3.4. Keeping this value in the dataset might bias our analyses. Instead, we can replace it with a null value since we're not sure what the true BMI for this individual is. This can be done with the function `replace`.

```{r}
                            # Vector, for which certain values will be replaced
framingham_df$BMI = replace(framingham_df$BMI, 
                            # Conditional for which values should be replaced
                            framingham_df$BMI < 5, 
                            # Value to use when the condition is TRUE
                            NA) 
```

To check that the low BMI value was replaced, we can check that no rows in the dataset have a BMI less than 5. The cell below should return a data frame with 0 rows.

```{r}
framingham_df %>% 
  filter(BMI < 5) 
```

# Creating Variables

## mutate()

Recall from Week 2 that we can use the `[]` and `$` operators to add new columns to a data frame.

For example, the both commands add a column called `age_months` to framingham_df. These values convert the age in years (contained in the `age` column) to age in months.

```{r}
age_years = framingham_df %>% pull(age)
# The next two lines do the same thing
framingham_df$age_months = age_years * 12 
framingham_df["age_months"] = age_years * 12 
```

To add a new column using `dplyr` functions, we can use `mutate()`. `mutate()` takes any number of arguments in the form `mutate(column_name = vector_of_values)`. For example, the following code could be used to create new `age_months` and `age_days` columns.

```{r}
framingham_df %>% 
  mutate(age_months = age * 12, 
         age_days = age * 365)
```

`mutate` can also be used to change the value of existing columns. Suppose we wanted to round the number of cigarettes per day to the nearest 10th and **replace** the values of `cigsPerDay` with their rounded equivalent.

```{r}
framingham_rounded_cigsPerDay = framingham_df %>% 
  mutate(cigsPerDay = round(cigsPerDay, digits = -1)) # digits = -1 specifies that we want to round to the nearest 10

# Shows distribution of cigsPerDay, should only be intervals of 10
table(framingham_rounded_cigsPerDay$cigsPerDay)
```

### if_else()

In some cases, we want to use an existing column to determine the values of a new column. `if_else()` can be used with `mutate` to set the values of a new variables based on a specific condition. It works similarly to if and else statements (see Week 2 for a refresher), and follows the structure `if_else(condition, value_for_true_condition, value_for_false_condition)`.

Suppose we wanted to create a new `sex` column that contains the values `male` or `female` based on the values contained in the `male` column (when 1 = male, 0 = female). The following code makes this new variable using `ifelse()`

```{r}
framingham_df %>% 
  mutate(sex = ifelse(condition = male == 1, true = "male", false = "female")) %>% 
  select(male, sex)
```

#### Practice Problem 1

Create a new variable `high_BMI` in framingham_df that takes on the value `1` if BMI is greater than or equal to 30 and `0` if BMI is less than 30.

```{r}
framingham_df %>% 
  mutate(high_BMI = ...(BMI >= 30, ..., ...))
```

### case_when()

`ifelse()` works well for creating binary variables but when we want to create a categorical variable with 3+ levels, `case_when()` is a more appropriate function.

Like `ifelse()`, `case_when()` reflects the logic that `if`, `else if`, and `else` follow. It takes any number of arguments that follow the structure `condition ~ new_value` (note how it uses a `~` instead of a `=`).

For example, the code below recodes `education` to more informative labels (0 = Unknown, 1 = Didn't graduate high school; 2 = High school diploma, GRE; 3 = Some college, 4 = Bachelor's degree or higher)

```{r}
framingham_df %>% 
  mutate(education_category = case_when(education == 0 ~ "Unknown", 
                                        education == 1 ~ "Didn't graduate high school", 
                                        education == 2 ~ "High school diploma", 
                                        education == 3 ~ "Some college", 
                                        education == 4 ~ "Bachelor's degree or highe")) %>% 
  select(education, education_category)
```

In calls of `case_when()`, conditions are evaluated in order; ex: the second condition is only assessed if the first condition evaluates to `FALSE`.

Below, we use `case_when()` to classify `cigsPerDay` into 4 groups: (1) 0 per day (2) 1-25 per day, (3) 26-50 per day, and (4) \>50 per day.

```{r}
framingham_df %>% 
  mutate(cigsPerDay_categories = 
           case_when(cigsPerDay == 0 ~ "0 per day",
                     # Sets value if cigsPerDay != 0 and cigsPerDay <= 25
                     cigsPerDay <= 25 ~ "1-25 per day",  
                     # Sets value if cigsPerDay != 0, cigsPerDay > 25, and cigsPerDay <= 50
                     cigsPerDay <= 50 ~ "26-50 per day", 
                     # Sets value if all other cases are FALSE
                     cigsPerDay > 50 ~ ">50 per day")) %>% 
  select(cigsPerDay, cigsPerDay_categories)
```

#### Practice Problem 2

Create a new variable `age_decades` in framingham_df that describes the decade that corresponds to each person's age (ie "20s" for ages 20-29, "30s" for people ages 30-39, etc). Assume that no one in the dataset is below 20 years old or above 79 years old.

```{r}
framingham_df %>% 
  mutate(age_decades = ...(age < 30 ~ ..., 
                           ...))
```

# Renaming Columns

Renaming columns can help improve the readability of a dataset. The `rename` function makes this process easy, and follows the structure `new_column_name = old_column_name`. Below, we can use `rename` to rename `sysBP` as `systolicBP` and `diaBP` as `diastolicBP`

```{r}
renamed_framingham = framingham_df %>% 
  rename(systolicBP = sysBP, 
         diastolicBP = diaBP)

renamed_framingham %>% select(systolicBP, diastolicBP)
```

After the columns have been renamed, the old column names can no longer be used in other commands. The code below will return an error.

```{r}
renamed_framingham %>% select(sysBP, diaBP)
```

#### Practice Problem 3

Rename the `education` column to `highest_education_completed`

```{r}
framingham_df %>% ...
```

# Joining Data Sets

The data we need for research studies might be spread across multiple different data frames, and need to be merged (or **joined**) before we can complete our analysis. These datasets should each have a column that contains the key or identifier that helps us link observations across different data frames.

There are many ways to join two data frames `x` and `y`. Join methods differ based on how they handle rows that are found in only one of data frames.

-   `left_join(x, y, by = c("key_name_in_x" = "key_name_in_y"))`: keeps all rows in `x` (the "left" dataset), and only rows in `y` (the "right" dataset) with `key_name_in_y` values that had a matching `key_name_in_x` value in `x`
-   `right_join(x, y, by = c("key_name_in_x" = "key_name_in_y"))`: keeps all rows in `y` (the "right" dataset), and only rows in `x` (the "left" dataset) with `key_name_in_x` values that had a matching `key_name_in_y` value in y
-   `full_join(x, y, by = c("key_name_in_x" = "key_name_in_y"))`: keeps all rows in `x` and `y`
-   `inner_join(x, y, by = c("key_name_in_x" = "key_name_in_y"))`: keeps only the rows in `x` and `y` that had a match between the datasets.

For a visual guide on how joins work, **we highly recommend that you read this section of the "R for Data Science" textbook: <https://r4ds.hadley.nz/joins.html#how-do-joins-work>**

## Examples

Below, we'll walk through how each of these join functions merge data from `framingham_df` and `zip_code_demog`. `framingham_df` contains person-level data, while `zip_code_demog` contains zip-code level demographic data. The `framingham_df` dataset contains a column called `zip_code` that can be linked to values in the `zip` column of `zip_code_demog`. Therefore, our "keys" are the zip codes because they link the two datasets. If you want to join two datasets, you need to specify the "key" that describes how rows in one should be matched to rows in another. By joining these two datasets by zip code, we can merge individual health outcome data with information on the social determinants of health in their communities.

However, there might be zip codes that are in `framingham_df` that aren't in `zip_code_demog` or vice versa. We can use the `!` and `%in%` operators to find zip codes that are only present in one of the datasets

```{r}
zips_in_framingham_df = framingham_df %>% pull(zip_code) %>% unique() %>% sort()
zips_in_demog = zip_code_demog %>% pull(zip) %>% unique() %>% sort()

# Selects items in zips_in_framingham_df that aren't in zips_in_demog
zips_only_in_framingham_df = zips_in_framingham_df[!(zips_in_framingham_df %in% zips_in_demog)]

# Selects items in zips_in_demog that aren't in zips_in_framingham_df
zips_only_in_demog = zips_in_demog[!(zips_in_demog %in% zips_in_framingham_df)]

paste("Zip codes only in framingham_df:", zips_only_in_framingham_df)
paste("Zip codes only in zip_code_demog:", zips_only_in_demog)
```

Because the keys in the two datasets do not perfectly match, we need to tell R which rows should be kept in the join and which do not need to be kept. We tell R which rows we want to keep using `left_join()`, `right_join()`, `full_join()`, or `inner_join()`. In all examples below, we'll treat `framingham_df` as our `x` or "left" dataset and `zip_code_demog` as our `y` or "right" dataset.

### left_join()

`left_join()` will keep all rows in `framingham_df`, and only rows in `zip_code_demog` that match zip codes contained in `framingham_df`. Run the cell below to complete a left join on the datasets.

```{r}
framingham_left_join = framingham_df %>% 
  left_join(zip_code_demog, by = c("zip_code" = "zip")) 
nrow(framingham_left_join)
```

The new data frame has all of the columns from `framingham_df`, but now includes the `total_population` and `median_hh_income` columns from `zip_code_demog.`

```{r}
colnames(framingham_left_join)
```

Note how `framingham_df` and `framingham_left_join` have the same number of rows

```{r}
nrow(framingham_df) == nrow(framingham_left_join)
```

However, we know that `framingham_df` included data for the zip code 01746 but not 01745. The resulting data set included all rows from `framingham_df`, so the patient who lives in 01746 will still have their individual data, but there will be missing values for `total_population` and `median_hh_income`.

```{r}
framingham_left_join %>% 
  filter(zip_code == "01746") %>% 
  select(zip_code, total_population, median_hh_income)
```

Since no patients lived in 01745 and it was not in `framingham_df`, there will be no rows in `framingham_left_join` for that zip code.

```{r}
framingham_left_join %>% 
  filter(zip_code == "01745") %>% 
  select(zip_code, total_population, median_hh_income)
```

### right_join()

`right_join()` will keep all rows in `zip_code_demog` and only rows in `framingham_df` that match zip codes contained in `zip_code_demog`. Run the cell below to complete a right join on the datasets.

```{r}
framingham_right_join = framingham_df %>% 
  right_join(zip_code_demog, by = c("zip_code" = "zip"))
nrow(framingham_right_join)
```

Unlike the result from our left join, the resulting dataset `framingham_right_join` has more rows than the original `zip_code_demog` dataframe.

```{r}
nrow(zip_code_demog) > nrow(framingham_right_join)
```

This is because there are many rows in `framingham_df` that match each row in `zip_code_demog`, since there are multiple people that live in each zip code.

We can see this more clearly by focusing on how `right_join` works for a single zip code.

The cell below extracts the demographic information for the zip code 01701.

```{r}
demog_01701 = zip_code_demog %>% filter(zip == "01701")
demog_01701
```

We can use `filter` and `nrow` on `framingham_df` to find the number of participants that have the zip code 01701.

```{r}
framingham_df %>% filter(zip_code == "01701") %>% nrow()
```

When we right join `framingham_df` with `demog_01701` by zip code, we end up only keep rows of `framingham_df` that have the zip code "01701".

```{r}
framingham_right_join_01701 = framingham_df %>% 
  right_join(demog_01701, by = c("zip_code" = "zip"))

nrow(framingham_right_join_01701)
```

The resulting table has 602 rows, where each row contains an individual patient. However, each person has the same zip-code level demographics. We can confirm this by showing that there's only one distinct combination of zip code, total population and household income.

```{r}
framingham_right_join_one_row %>% 
  select(zip_code, total_population, median_hh_income) %>% 
  distinct()
```

Let's go back to `framingham_right_join`, the result of the right join between `framingham_df` and `zip_code_demog`. The right join includes all rows from `zip_code_demog`, which contains data for the zip code 01745 where none of the patients live. Therefore, `framingham_right_join` will have data for 01745 but there will be missing values for the individual health factors.

```{r}
framingham_right_join %>% filter(zip_code == "01745")
```

`framingham_left_join` won't include data for zip code 01746 since it wasn't in the original `zip_code_demog` data frame even though patients live there.

```{r}
framingham_right_join %>% filter(zip_code == "01746")
```

### full_join()

If we wanted **all** zip codes that appear in the data sets, we can use a `full_join()`.

```{r}
framingham_full_join = framingham_df %>% 
  full_join(zip_code_demog, by = c("zip_code" = "zip"))
nrow(framingham_full_join)
```

Data for both 01746 (only in `framingham_df`) and 01745 (only in `zip_code_demog`) will be included in `framingham_full_join`.

The merged data will have missing zip code-level variables for 01746, and missing individual-level factors for 01745.

```{r}
framingham_full_join %>% 
  filter(zip_code == "01746") %>% 
  select(zip_code, total_population, median_hh_income)
```

```{r}
framingham_full_join %>% 
  filter(zip_code == "01745")
```

Analyses that use data created by a full join need to particularly careful of any missing values that are introduced in the merge process. In this case, if we wanted to use the number of rows in `framingham_full_join` to estimate the number of people per zip code, we might incorrectly count 1 person for the zip code 01745.

### inner_join()

If we wanted only zip codes that appear in **both** of the data sets, we can use a `inner_join()`.

```{r}
framingham_inner_join = framingham_df %>% 
  inner_join(zip_code_demog, by = c("zip_code" = "zip"))
nrow(framingham_inner_join)
```

In this case, neither 01745 nor 01746 will appear in the resulting data frame.

```{r}
framingham_inner_join %>% 
  filter(zip_code %in% c("01745", "01746"))
```

Analyses that use data created by a inner join need to be aware of which data points are dropped during the merge process. In some cases, the inner join could entirely remove patients with missing data leading to biased results.

## Practice Problem 4 (Challenge)

Create a new data frame `chd_income_df` that contains one row for each zip code represented in `framingham_df` and two columns: (1) `chd_prev`, the prevalence of CHD in the zip code and (2) the median household income of the zip code

Hint 1: Start by creating a data frame `chd_prev` with the prevalence of CHD for each zip code using `group_by`. (See Week 4 tutorial to remind yourself about grouping) Hint 2: We want our table to include one row for each zip code represented in `framingham_df`, even if there isn't household income data available for that zip code. What kind of join function should we use?

```{r}
chd_prev = framingham_df %>% group_by(...) %>% summarize(chd_prev = ...)
chd_income_df = chd_prev %>% ...(zip_code_demog, by = c("zip_code" = "zip"))
```

# Reshaping Data

There are many different ways to store the same data values.

In "long" data, there are multiple rows for each observation where each row contains a value for a single variable. Run the cell below to see an example of a long-format data frame.

```{r}
data.frame(participant_id = c(1, 1, 2, 2, 3, 3), 
           variable = c("var1", "var2", "var1", "var2", "var1", "var2"), 
           value = c(2, 7, 3, 5, 6, 8))
```

In "wide" data, there is one row for each observations that contains values for all recorded variables. Run the cell below to see an example of a long-format data frame.

```{r}
data.frame(participant_id = c(1, 2, 3), 
           var1 = c(2, 3, 6),
           var2 = c(7, 5, 8))
```

Over the next several weeks, we'll be using some functions that explicitly require data to be in a long or wide format. To switch between the two formats, we can use `pivot_wider` and `pivot_longer`.

## pivot_longer()

You might have noticed that `framingham_df` is currently in a wide format, since there is one row for each participant. We can use `pivot_longer` to convert it to a long format, which takes in the arguments.

-   `data`: a data frame, which contains only the observation id and the columns that contain variables that will make up rows in the long-format data frame
-   `cols`: a vector of characters, containing columns names corresponding to variables that will make up rows in the long-format data frame
-   (optional) `names_to`: a character, what the column containing variable names in the long-format data frame should be called
-   (optional) `values_to`: a character, what the column containing variable values in the long-format data frame should be called
-   **NOTE:** Remember that in a data frame, all values in a column must have the same data type. Selected columns for the long-format contain the same data type.

The cell below creates `framingham_long`, a long-format version of the framingham data that contains all numeric variables found in the original dataset.

```{r}
# Extract vectors of all variables names, excluding participant ID
num_variable_names = c("age", "cigsPerDay", "BPMeds", "totChol", "sysBP", "diaBP", "BMI", "heartRate", "glucose")

# Converts framingham_df to a long format
framingham_long = framingham_df %>% 
  distinct() %>% 
  select(id, all_of(num_variable_names)) %>% 
  pivot_longer(cols = all_of(num_variable_names), 
               names_to = "Variable", 
               values_to = "Values")

framingham_long
```

## pivot_wider()

We can then back-convert `framingham_long` to a wide version by using `pivot_wider()` which uses the arguments:

-   `data`: a data frame, in long format that contains the observation ID

-   `id_cols`: a character or vector of characters, the name(s) of columns that contain the observation ID

-   `names_from`: a character, the name of the column that contains variable names

-   `values_from`: a character, the name of the column that contains variable values

-   **NOTE:** Remember that in a data frame, all values in a column must have the same data type. Selected columns for the long-format contain the same data type.

The cell below creates `framingham_wide`, a wide-format version of the `framingham_long` data that contains all numeric variables found in the framingham dataset.

```{r}
framingham_wide = framingham_long %>% 
  pivot_wider(id_cols = "id", names_from = "Variable", values_from = "Values")

framingham_wide
```

# Summary

In this tutorial, you learned about the data manipulation methods that help make data sets more useful for your analyses.

Next week, you'll start applying your new R skillset to statistical analyses that mirror tasks you might encounter in health research.

If you have any questions about the contents of this tutorial, please post them in the \`Week 5 Tutorial\` thread.

# Resources

[Introduction to dplyr](https://dplyr.tidyverse.org/articles/dplyr.html)

[Data Wrangling with dplyr and tidyverse Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

R for Data Science Chapter 19: [Joins](https://r4ds.hadley.nz/joins)
